{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings \n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "# Load the pre-trained Yunet model\n",
    "model_path = \"face_detection_yunet_2023mar.onnx\"\n",
    "yunet = cv2.FaceDetectorYN_create(model_path, \"\", (320, 320))\n",
    "\n",
    "# Set input size for the Yunet model\n",
    "input_size = (320, 320)  # Yunet works best with this size\n",
    "yunet.setInputSize(input_size)\n",
    "\n",
    "# Open the webcam\n",
    "cap = cv2.VideoCapture(0)  # Change if using an external webcam\n",
    "cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)\n",
    "cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Could not open webcam.\")\n",
    "    exit()\n",
    "\n",
    "while True:\n",
    "    # Read a frame from the webcam\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"Error: Could not read frame.\")\n",
    "        break\n",
    "\n",
    "    # Get original frame size\n",
    "    orig_h, orig_w = frame.shape[:2]\n",
    "\n",
    "    # Resize frame to Yunet's expected input size\n",
    "    frame_resized = cv2.resize(frame, input_size)\n",
    "\n",
    "    # Detect faces\n",
    "    faces = yunet.detect(frame_resized)[1]  # Yunet returns (retval, faces), we need only faces\n",
    "\n",
    "    # Draw detected faces on the original frame (scaling bounding boxes)\n",
    "    if faces is not None:\n",
    "        for face in faces:\n",
    "            # Unpack face data (x, y, width, height, confidence)\n",
    "            x, y, w, h, confidence = face[:5]\n",
    "\n",
    "            # Scale bounding box back to original frame size\n",
    "            x = int(x * orig_w / input_size[0])\n",
    "            y = int(y * orig_h / input_size[1])\n",
    "            w = int(w * orig_w / input_size[0])\n",
    "            h = int(h * orig_h / input_size[1])\n",
    "\n",
    "            # Draw rectangle around the detected face\n",
    "            cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\n",
    "            # Add confidence score as text\n",
    "            cv2.putText(frame, f\"{confidence:.2f}\", (x, y - 10),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "\n",
    "    # Display the output frame\n",
    "    cv2.imshow(\"Face Detection - Yunet\", frame)\n",
    "\n",
    "    # Break the loop if 'q' is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the webcam and close windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

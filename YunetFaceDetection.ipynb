{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_labels(data_dir):\n",
    "    \"\"\"\n",
    "    Dynamically load labels based on folder structure.\n",
    "    :param data_dir: Path to the training images directory.\n",
    "    :return: A dictionary mapping IDs to labels.\n",
    "    \n",
    "    \"\"\"\n",
    "    labels = {}\n",
    "    for idx, folder_name in enumerate(sorted(os.listdir(data_dir)), start=1):\n",
    "        if os.path.isdir(os.path.join(data_dir, folder_name)):\n",
    "            labels[idx] = folder_name\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(data_dir):\n",
    "    \"\"\"\n",
    "    Prepare training data from a directory with subfolders for each person.\n",
    "    \n",
    "    :param data_dir: Path to the parent directory containing subfolders for each person.\n",
    "    :return: Tuple of faces and IDs.\n",
    "    \"\"\"\n",
    "    faces = []\n",
    "    ids = []\n",
    "    \n",
    "    # Iterate through each subfolder (person's name)\n",
    "    for person_name in os.listdir(data_dir):\n",
    "        person_folder = os.path.join(data_dir, person_name)\n",
    "        \n",
    "        if os.path.isdir(person_folder):  # Ensure it's a directory\n",
    "            # Iterate through each image in the person's folder\n",
    "            for image_name in os.listdir(person_folder):\n",
    "                image_path = os.path.join(person_folder, image_name)\n",
    "                \n",
    "                try:\n",
    "                    # Read the image, convert to grayscale, and prepare it for training\n",
    "                    img = Image.open(image_path).convert('L')  # Convert to grayscale\n",
    "                    image_np = np.array(img, 'uint8')  # Convert to NumPy array\n",
    "                    \n",
    "                    # Use the folder index as the ID (or customize if needed)\n",
    "                    id = list(os.listdir(data_dir)).index(person_name) + 1\n",
    "                    \n",
    "                    faces.append(image_np)\n",
    "                    ids.append(id)\n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing {image_path}: {e}\")\n",
    "                    \n",
    "    return faces, np.array(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_data(faces, ids):\n",
    "    \"\"\"\n",
    "    Perform data augmentation on the training dataset.\n",
    "    \n",
    "    :param faces: List of face images (NumPy arrays).\n",
    "    :param ids: Array of corresponding IDs for the face images.\n",
    "    :return: Augmented faces and IDs.\n",
    "    \"\"\"\n",
    "    augmented_faces = []\n",
    "    augmented_ids = []\n",
    "\n",
    "    for face, id in zip(faces, ids):\n",
    "        # Original image\n",
    "        augmented_faces.append(face)\n",
    "        augmented_ids.append(id)\n",
    "\n",
    "        # Flip horizontally\n",
    "        flipped_face = cv2.flip(face, 1)\n",
    "        augmented_faces.append(flipped_face)\n",
    "        augmented_ids.append(id)\n",
    "\n",
    "        # Add Gaussian blur\n",
    "        blurred_face = cv2.GaussianBlur(face, (5, 5), 0)\n",
    "        augmented_faces.append(blurred_face)\n",
    "        augmented_ids.append(id)\n",
    "\n",
    "        # Add brightness and contrast adjustment\n",
    "        adjusted_face = cv2.convertScaleAbs(face, alpha=1.2, beta=30)\n",
    "        augmented_faces.append(adjusted_face)\n",
    "        augmented_ids.append(id)\n",
    "\n",
    "    return augmented_faces, np.array(augmented_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split_data(faces, ids, test_size=0.2):\n",
    "    \"\"\"\n",
    "    Split the data into training and testing sets.\n",
    "    :param faces: List of face images (NumPy arrays).\n",
    "    :param ids: Array of corresponding IDs for the face images.\n",
    "    :param test_size: Proportion of the dataset to include in the test split.\n",
    "    :return: Training and testing sets (faces and ids).\n",
    "    \"\"\"\n",
    "    faces_train, faces_test, ids_train, ids_test = train_test_split(faces, ids, test_size=test_size, random_state=42)\n",
    "    return faces_train, faces_test, ids_train, ids_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_classifier(faces, ids, output_model=\"Yunetclassifier.xml\"):\n",
    "    print(\"Training classifier...\")\n",
    "    clf = cv2.face.LBPHFaceRecognizer_create()\n",
    "    clf.train(faces, ids)\n",
    "    clf.write(output_model)\n",
    "    print(f\"Training complete. Model saved as {output_model}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_accuracy(faces_test, ids_test):\n",
    "    \"\"\"\n",
    "    Calculate the accuracy of the classifier on the test set.\n",
    "    :param clf: Trained classifier.\n",
    "    :param faces_test: Test set faces.\n",
    "    :param ids_test: True labels for the test set.\n",
    "    :return: Accuracy score.\n",
    "    \"\"\"\n",
    "    clf = cv2.face.LBPHFaceRecognizer_create()\n",
    "    clf.read(\"Yunetclassifier.xml\")\n",
    "    predictions = []\n",
    "    for face in faces_test:\n",
    "        label, _ = clf.predict(face)\n",
    "        predictions.append(label)\n",
    "    accuracy = accuracy_score(ids_test, predictions)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_webcam(classifier, face_detector, labels):\n",
    "    \"\"\"\n",
    "    Capture video from webcam and predict faces in real-time using the trained classifier and ONNX-based face detector.\n",
    "\n",
    "    :param classifier: Trained LBPH face recognizer model.\n",
    "    :param face_detector: ONNX-based face detector.\n",
    "    :param labels: Dictionary mapping IDs to labels.\n",
    "    \"\"\"\n",
    "    print(\"Starting webcam...\")\n",
    "\n",
    "    video_capture = cv2.VideoCapture(0)\n",
    "\n",
    "    while True:\n",
    "        ret, img = video_capture.read()\n",
    "        if not ret:\n",
    "            print(\"Failed to capture image.\")\n",
    "            break\n",
    "\n",
    "        # Prepare image for the face detector\n",
    "        height, width, _ = img.shape\n",
    "        face_detector.setInputSize((width, height))\n",
    "\n",
    "        # Detect faces\n",
    "        _, faces = face_detector.detect(img)\n",
    "\n",
    "        if faces is not None:\n",
    "            for face in faces:\n",
    "                x, y, w, h = map(int, face[:4])  # Bounding box coordinates\n",
    "                face_roi = img[y:y+h, x:x+w]\n",
    "                gray_face = cv2.cvtColor(face_roi, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "                # Predict label\n",
    "                id, confidence = classifier.predict(gray_face)\n",
    "                confidence = int(100 * (1 - confidence / 300))\n",
    "\n",
    "                if confidence > 70 and id in labels:\n",
    "                    label = labels.get(id, \"UNKNOWN\")\n",
    "                    color = (0, 255, 0)  # Green for recognized faces\n",
    "                    cv2.rectangle(img, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "                    cv2.putText(img, f\"{label}\", (x, y-5), cv2.FONT_HERSHEY_SIMPLEX, 0.8, color, 1, cv2.LINE_AA)\n",
    "                else:\n",
    "                    label = \"UNKNOWN\"\n",
    "                    color = (0, 0, 255)  # Red for unknown faces\n",
    "                    cv2.rectangle(img, (x, y), (x+w, y+h), (255, 0, 0), 2)\n",
    "                    cv2.putText(img, label, (x, y-5), cv2.FONT_HERSHEY_SIMPLEX, 0.8, color, 1, cv2.LINE_AA)\n",
    "\n",
    "            # Draw the bounding box around the face\n",
    "            cv2.rectangle(img, (x, y), (x + w, y + h), color, 2)\n",
    "\n",
    "                \n",
    "\n",
    "        # Show the webcam feed with predictions\n",
    "        cv2.imshow(\"Webcam - Face Detection\", img)\n",
    "\n",
    "        # Exit on pressing 'Esc' key\n",
    "        if cv2.waitKey(1) == 27:  # 'Esc' key\n",
    "            break\n",
    "\n",
    "    video_capture.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_single_image(classifier, face_detector, labels, image_path):\n",
    "    \"\"\"\n",
    "    Predict the face in a single image using the trained classifier and FaceDetectorYN.\n",
    "\n",
    "    :param classifier: Trained LBPH face recognizer model.\n",
    "    :param face_detector: OpenCV FaceDetectorYN object.\n",
    "    :param labels: Dictionary mapping IDs to labels.\n",
    "    :param image_path: Path to the input image.\n",
    "    \"\"\"\n",
    "    # Load the image\n",
    "    img = cv2.imread(image_path)\n",
    "    if img is None:\n",
    "        print(f\"Failed to load image: {image_path}\")\n",
    "        return\n",
    "\n",
    "    # Convert to grayscale (LBPH requires grayscale input)\n",
    "    gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Detect faces using FaceDetectorYN\n",
    "    height, width = img.shape[:2]\n",
    "    face_detector.setInputSize((width, height))  # Update the input size for detection\n",
    "    _, faces = face_detector.detect(img)\n",
    "\n",
    "    if faces is not None and len(faces) > 0:\n",
    "        for face in faces:\n",
    "            x, y, w, h = map(int, face[:4])  # Extract bounding box coordinates\n",
    "            face_roi = gray_img[y:y+h, x:x+w]\n",
    "\n",
    "            # Predict label\n",
    "            id, confidence = classifier.predict(face_roi)\n",
    "\n",
    "            # Determine label based on confidence\n",
    "            if confidence > 50 and id in labels:\n",
    "                label = labels.get(id, \"UNKNOWN\")\n",
    "                color = (0, 255, 0)  # Green for recognized faces\n",
    "                cv2.rectangle(img, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "                cv2.putText(img, f\"{label}\", (x, y-5), cv2.FONT_HERSHEY_SIMPLEX, 0.8, color, 1, cv2.LINE_AA)\n",
    "            else:\n",
    "                label = \"UNKNOWN\"\n",
    "                color = (0, 0, 255)  # Red for unknown faces\n",
    "                cv2.rectangle(img, (x, y), (x+w, y+h), (255, 0, 0), 2)\n",
    "                cv2.putText(img, label, (x, y-5), cv2.FONT_HERSHEY_SIMPLEX, 0.8, color, 1, cv2.LINE_AA)\n",
    "\n",
    "            # Draw the bounding box around the face\n",
    "            cv2.rectangle(img, (x, y), (x + w, y + h), color, 2)\n",
    "    else:\n",
    "        print(\"No faces detected.\")\n",
    "\n",
    "    # Display the result (optional)\n",
    "    cv2.imshow(\"Prediction\", img)\n",
    "    cv2.waitKey()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths for training data\n",
    "training_data_dir = input(\"Enter the Folder Name\")  # Folder containing training images\n",
    "data_dir = training_data_dir\n",
    "\n",
    "labels = load_labels(data_dir)\n",
    "print(\"Labels loaded:\", labels)\n",
    "\n",
    "# Step 1: Load Training Data\n",
    "faces, ids = prepare_data(training_data_dir)\n",
    "\n",
    "# Step 2: Augment Data\n",
    "faces, ids = augment_data(faces, ids)\n",
    "print(f\"Data augmented. Total samples: {len(faces)}\")\n",
    "\n",
    "# Step 3: Train-Test Split\n",
    "faces_train, faces_test, ids_train, ids_test = train_test_split_data(faces, ids)\n",
    "print(f\"Training set size: {len(faces_train)}, Testing set size: {len(faces_test)}\")\n",
    "\n",
    "onnx_model_path = \"face_detection_yunet_2023mar.onnx\"\n",
    "# Step 1: Load Training Data\n",
    "faces, ids = prepare_data(training_data_dir)\n",
    "\n",
    "# Step 3: Train Classifier\n",
    "train_classifier(faces, ids, \"Yunetclassifier.xml\")\n",
    "\n",
    "# Step 4: Load ONNX Face Detector\n",
    "face_detector = cv2.FaceDetectorYN.create(onnx_model_path, \"\", (320, 320), 0.9, 0.3, 5000)\n",
    "clf = cv2.face.LBPHFaceRecognizer_create()\n",
    "clf.read(\"Yunetclassifier.xml\")\n",
    "\n",
    "# Step 5: Calculate Accuracy\n",
    "accuracy = calculate_accuracy(faces_test, ids_test)\n",
    "print(f\"Model accuracy on test data: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_webcam(clf, face_detector, labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
